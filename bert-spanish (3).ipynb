{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":86284,"databundleVersionId":9813435,"sourceType":"competition"},{"sourceId":9647790,"sourceType":"datasetVersion","datasetId":5892094},{"sourceId":139065,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":117750,"modelId":140985}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade transformers","metadata":{"execution":{"iopub.status.busy":"2024-10-17T21:31:57.757092Z","iopub.execute_input":"2024-10-17T21:31:57.757500Z","iopub.status.idle":"2024-10-17T21:32:21.862659Z","shell.execute_reply.started":"2024-10-17T21:31:57.757459Z","shell.execute_reply":"2024-10-17T21:32:21.861423Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nCollecting transformers\n  Downloading transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nDownloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: transformers\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.45.1\n    Uninstalling transformers-4.45.1:\n      Successfully uninstalled transformers-4.45.1\nSuccessfully installed transformers-4.45.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import TrOCRProcessor, VisionEncoderDecoderModel\nfrom transformers import Trainer, TrainingArguments\nfrom transformers import VisionEncoderDecoderModel, AutoProcessor\nfrom datasets import load_dataset\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport os\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import DataLoader, Dataset\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm_notebook as tqdm\nfrom transformers import AdamW\nimport torch.nn.functional as F\ndevice='cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-10-17T21:32:21.865087Z","iopub.execute_input":"2024-10-17T21:32:21.865965Z","iopub.status.idle":"2024-10-17T21:32:41.294608Z","shell.execute_reply.started":"2024-10-17T21:32:21.865916Z","shell.execute_reply":"2024-10-17T21:32:41.293605Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load the model and processor\nmodel = VisionEncoderDecoderModel.from_pretrained(\"qantev/trocr-small-spanish\")\nprocessor = AutoProcessor.from_pretrained(\"qantev/trocr-small-spanish\")\ntokenizer = TrOCRProcessor.from_pretrained('qantev/trocr-small-spanish')\n","metadata":{"execution":{"iopub.status.busy":"2024-10-18T00:23:57.543982Z","iopub.execute_input":"2024-10-18T00:23:57.544360Z","iopub.status.idle":"2024-10-18T00:24:01.662670Z","shell.execute_reply.started":"2024-10-18T00:23:57.544323Z","shell.execute_reply":"2024-10-18T00:24:01.661844Z"},"trusted":true},"outputs":[],"execution_count":146},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"/kaggle/input/trocr-small/pytorch/default/1/model_weights_grayscale_contrast.pth\"))","metadata":{"execution":{"iopub.status.busy":"2024-10-18T00:24:01.664370Z","iopub.execute_input":"2024-10-18T00:24:01.664697Z","iopub.status.idle":"2024-10-18T00:24:02.016439Z","shell.execute_reply.started":"2024-10-18T00:24:01.664662Z","shell.execute_reply":"2024-10-18T00:24:02.015548Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/446732016.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"/kaggle/input/trocr-small/pytorch/default/1/model_weights_grayscale_contrast.pth\"))\n","output_type":"stream"},{"execution_count":147,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":147},{"cell_type":"code","source":"path = \"/kaggle/input/extra-spanish-text-1k/train_texts.csv\"\ndf1 = pd.read_csv(path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:36:52.755608Z","iopub.execute_input":"2024-10-17T22:36:52.756327Z","iopub.status.idle":"2024-10-17T22:36:52.766563Z","shell.execute_reply.started":"2024-10-17T22:36:52.756280Z","shell.execute_reply":"2024-10-17T22:36:52.765654Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"df1.columns.values[0] = 'unique Id'  # Change the first column heading to \"unique Id\"\ndf1 = df1.rename(columns={'transcription': 'nans'})\ndf1 = df1.rename(columns={'unique Id': 'transcription'})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:36:54.011919Z","iopub.execute_input":"2024-10-17T22:36:54.012645Z","iopub.status.idle":"2024-10-17T22:36:54.018710Z","shell.execute_reply.started":"2024-10-17T22:36:54.012599Z","shell.execute_reply":"2024-10-17T22:36:54.017674Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"df1[\"unique Id\"] = range(len(df1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:36:55.241363Z","iopub.execute_input":"2024-10-17T22:36:55.242216Z","iopub.status.idle":"2024-10-17T22:36:55.247007Z","shell.execute_reply.started":"2024-10-17T22:36:55.242174Z","shell.execute_reply":"2024-10-17T22:36:55.246038Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"df1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:36:56.836654Z","iopub.execute_input":"2024-10-17T22:36:56.837389Z","iopub.status.idle":"2024-10-17T22:36:56.848555Z","shell.execute_reply.started":"2024-10-17T22:36:56.837349Z","shell.execute_reply":"2024-10-17T22:36:56.847632Z"}},"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"                                           transcription  nans  unique Id\ntranscription_0       to, sin saber tres virtud tiene. Y   NaN          0\ntranscription_1        tos juicios de darme tiempo, para   NaN          1\ntranscription_2         que en vuestra educación lo mani   NaN          2\ntranscription_3     sestalle, pues me hallo tantos meses   NaN          3\ntranscription_4        ha rendida en esta cama, a una en   NaN          4\n...                                                  ...   ...        ...\ntranscription_996       en sus tierras, en sus naciones.   NaN        996\ntranscription_997       También le nacieron hijos á Sem,   NaN        997\ntranscription_998                  de todos los hijos de   NaN        998\ntranscription_999          estos fueron hijos de Joctán.   NaN        999\ntranscription_1000               son las familias de Noé   NaN       1000\n\n[1001 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transcription</th>\n      <th>nans</th>\n      <th>unique Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>transcription_0</th>\n      <td>to, sin saber tres virtud tiene. Y</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>transcription_1</th>\n      <td>tos juicios de darme tiempo, para</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>transcription_2</th>\n      <td>que en vuestra educación lo mani</td>\n      <td>NaN</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>transcription_3</th>\n      <td>sestalle, pues me hallo tantos meses</td>\n      <td>NaN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>transcription_4</th>\n      <td>ha rendida en esta cama, a una en</td>\n      <td>NaN</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>transcription_996</th>\n      <td>en sus tierras, en sus naciones.</td>\n      <td>NaN</td>\n      <td>996</td>\n    </tr>\n    <tr>\n      <th>transcription_997</th>\n      <td>También le nacieron hijos á Sem,</td>\n      <td>NaN</td>\n      <td>997</td>\n    </tr>\n    <tr>\n      <th>transcription_998</th>\n      <td>de todos los hijos de</td>\n      <td>NaN</td>\n      <td>998</td>\n    </tr>\n    <tr>\n      <th>transcription_999</th>\n      <td>estos fueron hijos de Joctán.</td>\n      <td>NaN</td>\n      <td>999</td>\n    </tr>\n    <tr>\n      <th>transcription_1000</th>\n      <td>son las familias de Noé</td>\n      <td>NaN</td>\n      <td>1000</td>\n    </tr>\n  </tbody>\n</table>\n<p>1001 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":84},{"cell_type":"code","source":"path1 = \"/kaggle/input/ai-of-god-3/Public_data/train.csv\"\nai_train = pd.read_csv(path1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:27.521660Z","iopub.execute_input":"2024-10-17T22:09:27.522041Z","iopub.status.idle":"2024-10-17T22:09:27.553487Z","shell.execute_reply.started":"2024-10-17T22:09:27.522004Z","shell.execute_reply":"2024-10-17T22:09:27.552640Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"ai_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:28.213961Z","iopub.execute_input":"2024-10-17T22:09:28.214648Z","iopub.status.idle":"2024-10-17T22:09:28.227893Z","shell.execute_reply.started":"2024-10-17T22:09:28.214600Z","shell.execute_reply":"2024-10-17T22:09:28.226660Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"              unique Id                                      transcription\n0      Rodrigo_00006_00                             Historia De España_Del\n1      Rodrigo_00006_01                               Arçobispo. Do Rodri_\n2      Rodrigo_00006_02                               go. Traducida En Ro_\n3      Rodrigo_00006_03                                              mançe\n4      Rodrigo_00008_00              E ste es el libro de la Cronica de es\n...                 ...                                                ...\n15005  Rodrigo_00620_19  mes En zelo de la fe & partian lo que Auian a ...\n15006  Rodrigo_00620_20  an menester. & se parauan muy rezios En los pe...\n15007  Rodrigo_00620_21  suffrian mucho trabajo por amor de dios / del ...\n15008  Rodrigo_00620_22  tilla estos prelados, don Rodrigo Arçobispo de...\n15009  Rodrigo_00620_23  tello obispo de palencia, don Rodrigo obispo d...\n\n[15010 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique Id</th>\n      <th>transcription</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Rodrigo_00006_00</td>\n      <td>Historia De España_Del</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Rodrigo_00006_01</td>\n      <td>Arçobispo. Do Rodri_</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Rodrigo_00006_02</td>\n      <td>go. Traducida En Ro_</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Rodrigo_00006_03</td>\n      <td>mançe</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Rodrigo_00008_00</td>\n      <td>E ste es el libro de la Cronica de es</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15005</th>\n      <td>Rodrigo_00620_19</td>\n      <td>mes En zelo de la fe &amp; partian lo que Auian a ...</td>\n    </tr>\n    <tr>\n      <th>15006</th>\n      <td>Rodrigo_00620_20</td>\n      <td>an menester. &amp; se parauan muy rezios En los pe...</td>\n    </tr>\n    <tr>\n      <th>15007</th>\n      <td>Rodrigo_00620_21</td>\n      <td>suffrian mucho trabajo por amor de dios / del ...</td>\n    </tr>\n    <tr>\n      <th>15008</th>\n      <td>Rodrigo_00620_22</td>\n      <td>tilla estos prelados, don Rodrigo Arçobispo de...</td>\n    </tr>\n    <tr>\n      <th>15009</th>\n      <td>Rodrigo_00620_23</td>\n      <td>tello obispo de palencia, don Rodrigo obispo d...</td>\n    </tr>\n  </tbody>\n</table>\n<p>15010 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"train_df = df1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:30.252860Z","iopub.execute_input":"2024-10-17T22:09:30.253237Z","iopub.status.idle":"2024-10-17T22:09:30.257435Z","shell.execute_reply.started":"2024-10-17T22:09:30.253200Z","shell.execute_reply":"2024-10-17T22:09:30.256527Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom collections import Counter\n\n# Function to clean and tokenize transcriptions\ndef tokenize_transcription(transcription):\n    # Lowercase the text, remove punctuation, and split by whitespace\n    transcription = transcription.lower()\n    words = re.findall(r'\\b\\w+\\b', transcription)  # Extract words\n    return words\n\n# Create a list to store all words\nall_words = []\ntranscription = train_df[\"transcription\"]\ntranscription1 = ai_train[\"transcription\"]\n# Iterate through your dataset and tokenize each transcription\n\nfor line in transcription:\n    words = tokenize_transcription(line)\n    all_words.extend(words)\n\nfor line in transcription1:\n    words = tokenize_transcription(line)\n    all_words.extend(words)\n# Count the frequency of each word\nword_counts = Counter(all_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:31.381536Z","iopub.execute_input":"2024-10-17T22:09:31.382246Z","iopub.status.idle":"2024-10-17T22:09:31.521019Z","shell.execute_reply.started":"2024-10-17T22:09:31.382204Z","shell.execute_reply":"2024-10-17T22:09:31.519979Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"load_old_spanish_dictionary = list(word_counts.keys())\n\n# Print some information\nprint(f\"Total unique words: {len(load_old_spanish_dictionary)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:33.257364Z","iopub.execute_input":"2024-10-17T22:09:33.258123Z","iopub.status.idle":"2024-10-17T22:09:33.267328Z","shell.execute_reply.started":"2024-10-17T22:09:33.258081Z","shell.execute_reply":"2024-10-17T22:09:33.266127Z"}},"outputs":[{"name":"stdout","text":"Total unique words: 13336\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"from transformers import BertTokenizer\nfrom collections import defaultdict\n\n# Load BERT Spanish tokenizer\ntokenizer = BertTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased')\n\n# Extract the BERT vocabulary (token IDs mapped to words)\nbert_vocab = set(tokenizer.get_vocab().keys())\n\n# Use the Old Spanish dictionary as a set (assuming load_old_spanish_dictionary is a list)\nold_spanish_dictionary = set(load_old_spanish_dictionary)  # Use the list directly\n\n# Union of BERT and Old Spanish dictionaries\ncombined_vocabulary = bert_vocab.union(old_spanish_dictionary)\n\n# Check some words from combined vocabulary\nprint(f\"Size of Combined Vocabulary: {len(combined_vocabulary)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:09:34.563479Z","iopub.execute_input":"2024-10-17T22:09:34.564158Z","iopub.status.idle":"2024-10-17T22:09:34.789030Z","shell.execute_reply.started":"2024-10-17T22:09:34.564114Z","shell.execute_reply":"2024-10-17T22:09:34.788003Z"}},"outputs":[{"name":"stdout","text":"Size of Combined Vocabulary: 41476\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/ai-of-god-3/Public_data/test.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:09:44.093397Z","iopub.execute_input":"2024-10-17T22:09:44.093800Z","iopub.status.idle":"2024-10-17T22:09:44.105541Z","shell.execute_reply.started":"2024-10-17T22:09:44.093761Z","shell.execute_reply":"2024-10-17T22:09:44.104728Z"},"trusted":true},"outputs":[],"execution_count":59},{"cell_type":"code","source":"test_path = '/kaggle/input/ai-of-god-3/Public_data/test_images'\n\n# Function to convert unique ID into correct image path\ndef construct_image_path(unique_id):\n    parts = unique_id.split('_')\n    page_number = parts[1]\n    l_number = parts[3] \n    \n    image_path = os.path.join(test_path, f'Page_{page_number}', f'L_{l_number}.png')\n    return image_path\n\ntest_df['image_path'] = test_df['unique Id'].apply(construct_image_path)\n\n# Check the resulting dataframe\nprint(test_df[[ 'image_path']].head())","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:09:45.506814Z","iopub.execute_input":"2024-10-17T22:09:45.507184Z","iopub.status.idle":"2024-10-17T22:09:45.518353Z","shell.execute_reply.started":"2024-10-17T22:09:45.507151Z","shell.execute_reply":"2024-10-17T22:09:45.517464Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                          image_path\n0  /kaggle/input/ai-of-god-3/Public_data/test_ima...\n1  /kaggle/input/ai-of-god-3/Public_data/test_ima...\n2  /kaggle/input/ai-of-god-3/Public_data/test_ima...\n3  /kaggle/input/ai-of-god-3/Public_data/test_ima...\n4  /kaggle/input/ai-of-god-3/Public_data/test_ima...\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"extra_df = pd.read_csv(\"/kaggle/input/extra-spanish-text-1k/train_texts.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:13:12.742766Z","iopub.execute_input":"2024-10-17T22:13:12.743204Z","iopub.status.idle":"2024-10-17T22:13:12.753426Z","shell.execute_reply.started":"2024-10-17T22:13:12.743164Z","shell.execute_reply":"2024-10-17T22:13:12.752535Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"extra_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:15:49.698917Z","iopub.execute_input":"2024-10-17T22:15:49.699898Z","iopub.status.idle":"2024-10-17T22:15:49.713753Z","shell.execute_reply.started":"2024-10-17T22:15:49.699844Z","shell.execute_reply":"2024-10-17T22:15:49.712692Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"                                               unique Id  transcription\ntranscription_0       to, sin saber tres virtud tiene. Y            NaN\ntranscription_1        tos juicios de darme tiempo, para            NaN\ntranscription_2         que en vuestra educación lo mani            NaN\ntranscription_3     sestalle, pues me hallo tantos meses            NaN\ntranscription_4        ha rendida en esta cama, a una en            NaN\n...                                                  ...            ...\ntranscription_996       en sus tierras, en sus naciones.            NaN\ntranscription_997       También le nacieron hijos á Sem,            NaN\ntranscription_998                  de todos los hijos de            NaN\ntranscription_999          estos fueron hijos de Joctán.            NaN\ntranscription_1000               son las familias de Noé            NaN\n\n[1001 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique Id</th>\n      <th>transcription</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>transcription_0</th>\n      <td>to, sin saber tres virtud tiene. Y</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_1</th>\n      <td>tos juicios de darme tiempo, para</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_2</th>\n      <td>que en vuestra educación lo mani</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_3</th>\n      <td>sestalle, pues me hallo tantos meses</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_4</th>\n      <td>ha rendida en esta cama, a una en</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>transcription_996</th>\n      <td>en sus tierras, en sus naciones.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_997</th>\n      <td>También le nacieron hijos á Sem,</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_998</th>\n      <td>de todos los hijos de</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_999</th>\n      <td>estos fueron hijos de Joctán.</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>transcription_1000</th>\n      <td>son las familias de Noé</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>1001 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"df1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:34:45.356366Z","iopub.execute_input":"2024-10-17T22:34:45.356757Z","iopub.status.idle":"2024-10-17T22:34:45.374940Z","shell.execute_reply.started":"2024-10-17T22:34:45.356718Z","shell.execute_reply":"2024-10-17T22:34:45.373839Z"}},"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"                                           transcription  nans  unique Id  \\\ntranscription_0       to, sin saber tres virtud tiene. Y   NaN          0   \ntranscription_1        tos juicios de darme tiempo, para   NaN          1   \ntranscription_2         que en vuestra educación lo mani   NaN          2   \ntranscription_3     sestalle, pues me hallo tantos meses   NaN          3   \ntranscription_4        ha rendida en esta cama, a una en   NaN          4   \n...                                                  ...   ...        ...   \ntranscription_996       en sus tierras, en sus naciones.   NaN        996   \ntranscription_997       También le nacieron hijos á Sem,   NaN        997   \ntranscription_998                  de todos los hijos de   NaN        998   \ntranscription_999          estos fueron hijos de Joctán.   NaN        999   \ntranscription_1000               son las familias de Noé   NaN       1000   \n\n                                                           image_path  \ntranscription_0     /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_1     /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_2     /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_3     /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_4     /kaggle/input/extra-spanish-text-1k/train_imag...  \n...                                                               ...  \ntranscription_996   /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_997   /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_998   /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_999   /kaggle/input/extra-spanish-text-1k/train_imag...  \ntranscription_1000  /kaggle/input/extra-spanish-text-1k/train_imag...  \n\n[1001 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transcription</th>\n      <th>nans</th>\n      <th>unique Id</th>\n      <th>image_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>transcription_0</th>\n      <td>to, sin saber tres virtud tiene. Y</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_1</th>\n      <td>tos juicios de darme tiempo, para</td>\n      <td>NaN</td>\n      <td>1</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_2</th>\n      <td>que en vuestra educación lo mani</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_3</th>\n      <td>sestalle, pues me hallo tantos meses</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_4</th>\n      <td>ha rendida en esta cama, a una en</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>transcription_996</th>\n      <td>en sus tierras, en sus naciones.</td>\n      <td>NaN</td>\n      <td>996</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_997</th>\n      <td>También le nacieron hijos á Sem,</td>\n      <td>NaN</td>\n      <td>997</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_998</th>\n      <td>de todos los hijos de</td>\n      <td>NaN</td>\n      <td>998</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_999</th>\n      <td>estos fueron hijos de Joctán.</td>\n      <td>NaN</td>\n      <td>999</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n    <tr>\n      <th>transcription_1000</th>\n      <td>son las familias de Noé</td>\n      <td>NaN</td>\n      <td>1000</td>\n      <td>/kaggle/input/extra-spanish-text-1k/train_imag...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1001 rows × 4 columns</p>\n</div>"},"metadata":{}}],"execution_count":80},{"cell_type":"code","source":"extra_path = '/kaggle/input/extra-spanish-text-1k/train_images/train_images'\n# Base directory for the images\nbase_image_path = '/kaggle/input/extra-spanish-text-1k/train_images/train_images/'\n\n# Loop over the dataset to create image paths\nimage_paths = []\n\nfor i, row in df1.iterrows():\n    # Construct the image path based on the unique ID\n    image_path = f\"{base_image_path}transcription_{row['unique Id']}.png\"\n    image_paths.append(image_path)\n\n# Add the image paths to your dataframe\ndf1['image_path'] = image_paths\n\n# Check the first few entries to confirm the paths\nprint(df1[['unique Id', 'image_path']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T22:37:19.541503Z","iopub.execute_input":"2024-10-17T22:37:19.542157Z","iopub.status.idle":"2024-10-17T22:37:19.609422Z","shell.execute_reply.started":"2024-10-17T22:37:19.542114Z","shell.execute_reply":"2024-10-17T22:37:19.608439Z"}},"outputs":[{"name":"stdout","text":"                 unique Id                                         image_path\ntranscription_0          0  /kaggle/input/extra-spanish-text-1k/train_imag...\ntranscription_1          1  /kaggle/input/extra-spanish-text-1k/train_imag...\ntranscription_2          2  /kaggle/input/extra-spanish-text-1k/train_imag...\ntranscription_3          3  /kaggle/input/extra-spanish-text-1k/train_imag...\ntranscription_4          4  /kaggle/input/extra-spanish-text-1k/train_imag...\n","output_type":"stream"}],"execution_count":86},{"cell_type":"code","source":"from torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:09:48.073445Z","iopub.execute_input":"2024-10-17T22:09:48.073839Z","iopub.status.idle":"2024-10-17T22:09:48.078034Z","shell.execute_reply.started":"2024-10-17T22:09:48.073802Z","shell.execute_reply":"2024-10-17T22:09:48.077129Z"},"trusted":true},"outputs":[],"execution_count":61},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T22:09:48.392701Z","iopub.execute_input":"2024-10-17T22:09:48.393535Z","iopub.status.idle":"2024-10-17T22:09:48.488099Z","shell.execute_reply.started":"2024-10-17T22:09:48.393496Z","shell.execute_reply":"2024-10-17T22:09:48.487160Z"},"trusted":true},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"VisionEncoderDecoderModel(\n  (encoder): DeiTModel(\n    (embeddings): DeiTEmbeddings(\n      (patch_embeddings): DeiTPatchEmbeddings(\n        (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n    (encoder): DeiTEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x DeiTLayer(\n          (attention): DeiTAttention(\n            (attention): DeiTSelfAttention(\n              (query): Linear(in_features=384, out_features=384, bias=True)\n              (key): Linear(in_features=384, out_features=384, bias=True)\n              (value): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n            (output): DeiTSelfOutput(\n              (dense): Linear(in_features=384, out_features=384, bias=True)\n              (dropout): Dropout(p=0.0, inplace=False)\n            )\n          )\n          (intermediate): DeiTIntermediate(\n            (dense): Linear(in_features=384, out_features=1536, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): DeiTOutput(\n            (dense): Linear(in_features=1536, out_features=384, bias=True)\n            (dropout): Dropout(p=0.0, inplace=False)\n          )\n          (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n          (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n    (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n    (pooler): DeiTPooler(\n      (dense): Linear(in_features=384, out_features=384, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (decoder): TrOCRForCausalLM(\n    (model): TrOCRDecoderWrapper(\n      (decoder): TrOCRDecoder(\n        (embed_tokens): TrOCRScaledWordEmbedding(64044, 256, padding_idx=1)\n        (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256)\n        (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n        (layers): ModuleList(\n          (0-5): 6 x TrOCRDecoderLayer(\n            (self_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (activation_fn): ReLU()\n            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (encoder_attn): TrOCRAttention(\n              (k_proj): Linear(in_features=384, out_features=256, bias=True)\n              (v_proj): Linear(in_features=384, out_features=256, bias=True)\n              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n            )\n            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n          )\n        )\n      )\n    )\n    (output_projection): Linear(in_features=256, out_features=64044, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"# predictions = []\n\n# model.eval()\n\n# with torch.no_grad():\n#     for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Inference\"):\n#         image_path = row['image_path']\n        \n#         # Open and preprocess the image (convert to grayscale, normalize, etc.)\n#         image = Image.open(image_path).convert(\"RGB\")\n        \n#         # Apply the transformations (grayscale, normalize, and ToTensor)\n#         transform = transforms.Compose([\n#             transforms.Grayscale(num_output_channels=3),\n#             transforms.ToTensor()\n#         ])\n        \n#         image = transform(image)\n\n#         image_g = image.to(device)\n\n#         mask = image_g < 0.6875\n#         image_g[mask] = 0.0\n#         image_g[~mask] = 1.0\n        \n#         # Process the image using the processor\n#         pixel_values = processor(image_g, return_tensors=\"pt\", do_rescale=False).pixel_values.to(device)\n\n#         # Generate output\n#         outputs = model.generate(pixel_values)\n\n#         # Decode the predicted string\n#         predicted_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n#         # Append the results\n#         predictions.append({\n#             'unique Id': row['unique Id'],  # Ensure 'unique Id' is correctly named in the dataframe\n#             'prediction': predicted_string\n#         })\n\n# # Create DataFrame for predictions\n# predictions_df = pd.DataFrame(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T18:56:54.121407Z","iopub.execute_input":"2024-10-17T18:56:54.121702Z","iopub.status.idle":"2024-10-17T18:56:54.126568Z","shell.execute_reply.started":"2024-10-17T18:56:54.12167Z","shell.execute_reply":"2024-10-17T18:56:54.125865Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nfrom PIL import Image\nimport pandas as pd\nimport torchvision.transforms as transforms\n\n# Assuming 'device' and 'model' are defined earlier, for example:\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)  # Move model to the device\n\npredictions = []\n\n# Set the model to evaluation mode\nmodel.eval()\n\nwith torch.no_grad():  # No need to calculate gradients during inference\n    for _, row in tqdm(df1.iterrows(), total=len(df1), desc=\"Inference\"):\n        image_path = row['image_path']\n        \n        # Open the image as grayscale\n        image = Image.open(image_path).convert(\"L\")  # 'L' mode for grayscale\n        \n        # Transform the image to tensor format\n        transform = transforms.ToTensor()\n        image_tensor = transform(image)  # Shape: [1, H, W] for grayscale\n        \n        # Stack the grayscale image to 3 channels to match model input\n        image_stacked = torch.cat([image_tensor] * 3, dim=0)  # Shape: [3, H, W]\n\n        # Apply threshold transformation\n        mask = image_stacked < 0.6875\n        image_stacked[mask] = 0.0\n        image_stacked[~mask] = 1.0\n\n        # Reshape the image for batch processing\n        image_stacked = image_stacked.unsqueeze(0)  # Add batch dimension, Shape: [1, 3, H, W]\n\n        # Process the image using the processor without rescaling (as per your requirement)\n        pixel_values = processor(image_stacked, return_tensors=\"pt\", do_rescale=False).pixel_values.to(device)\n        \n        # Generate the output using the model\n        outputs = model.generate(pixel_values)\n\n        # Decode the generated output to get the predicted string\n        predicted_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Append the results to predictions list\n        predictions.append({\n            'unique Id': row['unique Id'],  # Ensure 'unique Id' matches your column name\n            'prediction': predicted_string\n        })\n\n# Create a DataFrame for storing predictions\npredictions_df = pd.DataFrame(predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T23:38:59.950042Z","iopub.execute_input":"2024-10-17T23:38:59.950433Z","iopub.status.idle":"2024-10-17T23:41:54.515891Z","shell.execute_reply.started":"2024-10-17T23:38:59.950389Z","shell.execute_reply":"2024-10-17T23:41:54.514752Z"}},"outputs":[{"name":"stderr","text":"Inference:   0%|          | 0/1001 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nInference: 100%|██████████| 1001/1001 [02:54<00:00,  5.74it/s]\n","output_type":"stream"}],"execution_count":127},{"cell_type":"code","source":"predictions_df[\"prediction\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T23:41:54.517857Z","iopub.execute_input":"2024-10-17T23:41:54.518534Z","iopub.status.idle":"2024-10-17T23:41:54.526902Z","shell.execute_reply.started":"2024-10-17T23:41:54.518485Z","shell.execute_reply":"2024-10-17T23:41:54.525628Z"}},"outputs":[{"execution_count":128,"output_type":"execute_result","data":{"text/plain":"0            ro su saber reis Virtuo tiene y\n1          tos juicios de darne tiempo, para\n2           que en vuestra educación lo mani\n3       sestalle, pues me hallo tantos mesos\n4           ña astoria En esta casa a día. E\n                        ...                 \n996         En sus fistras. En sus Nacionals\n997         También le nacieron hijos á Sem,\n998                    de todos los hijos de\n999            estos fueron hijos de locián.\n1000                 son las familias de Noé\nName: prediction, Length: 1001, dtype: object"},"metadata":{}}],"execution_count":128},{"cell_type":"code","source":"real_texts = train_df['transcription'].tolist()  # Assuming 'transcription' is the column name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-17T23:53:03.786406Z","iopub.execute_input":"2024-10-17T23:53:03.787226Z","iopub.status.idle":"2024-10-17T23:53:03.791796Z","shell.execute_reply.started":"2024-10-17T23:53:03.787182Z","shell.execute_reply":"2024-10-17T23:53:03.790786Z"}},"outputs":[],"execution_count":137},{"cell_type":"code","source":"from transformers import BartForConditionalGeneration, BartTokenizer\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import AdamW\nimport torch\nfrom sklearn.model_selection import train_test_split\n\n# Define your custom Dataset class\nclass PredictionLabelDataset(Dataset):\n    def __init__(self, predictions, real_texts, tokenizer, max_length=128):\n        self.predictions = predictions\n        self.real_texts = real_texts\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.predictions)\n\n    def __getitem__(self, idx):\n        prediction = str(self.predictions[idx])\n        real_text = str(self.real_texts[idx])\n        \n        # Tokenize inputs and outputs (real_text as labels)\n        input_encoding = self.tokenizer(prediction, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n        label_encoding = self.tokenizer(real_text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')\n\n        # Replace padding tokens in labels with -100, which is ignored by loss function\n        labels = label_encoding['input_ids'].squeeze()\n        labels[labels == tokenizer.pad_token_id] = -100\n\n        return {\n            'input_ids': input_encoding['input_ids'].squeeze(),  # Remove batch dimension\n            'attention_mask': input_encoding['attention_mask'].squeeze(),\n            'labels': labels  # Labels are real text tokenized\n        }\n\n# Load your data (ensure your dataframe has 'predictions' and 'transcription' columns)\npredictions = predictions_df['prediction'].tolist()  \nreal_texts = df1['transcription'].tolist()  \n\n# Initialize the tokenizer and model for BART\ntokenizer = BartTokenizer.from_pretrained('facebook/bart-base')\n\n# Split the data into training and validation sets\ntrain_predictions, val_predictions, train_real_texts, val_real_texts = train_test_split(\n    predictions, real_texts, test_size=0.1, random_state=42\n)\n\n# Create Dataset instances for training and validation\ntrain_dataset = PredictionLabelDataset(train_predictions, train_real_texts, tokenizer)\nval_dataset = PredictionLabelDataset(val_predictions, val_real_texts, tokenizer)\n\n# Create DataLoaders for training and validation\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n\n# Load the BART model for conditional generation\nmodel = BartForConditionalGeneration.from_pretrained('facebook/bart-base')\n\n# Move model to GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\n# Set up the optimizer\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# Training loop\nnum_epochs = 3\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n\n    # Training phase\n    for batch in train_loader:\n        batch = {key: value.to(device) for key, value in batch.items()}\n        \n        # Forward pass\n        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n        loss = outputs.loss\n        total_loss += loss.item()\n\n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {total_loss/len(train_loader)}\")\n\n    # Validation phase\n    model.eval()\n    val_loss = 0\n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {key: value.to(device) for key, value in batch.items()}\n            \n            outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'], labels=batch['labels'])\n            val_loss += outputs.loss.item()\n    \n    print(f\"Validation Loss: {val_loss/len(val_loader)}\")\n\n# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_bart_model\")\ntokenizer.save_pretrained(\"fine_tuned_bart_model\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:31:41.254670Z","iopub.execute_input":"2024-10-18T00:31:41.255679Z","iopub.status.idle":"2024-10-18T00:32:37.365504Z","shell.execute_reply.started":"2024-10-18T00:31:41.255635Z","shell.execute_reply":"2024-10-18T00:32:37.364598Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3, Loss: 1.2018372458324098\nValidation Loss: 0.9980443886348179\nEpoch 2/3, Loss: 0.7945075960535752\nValidation Loss: 0.9059946196419852\nEpoch 3/3, Loss: 0.6450232562788746\nValidation Loss: 0.9090357933725629\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":154,"output_type":"execute_result","data":{"text/plain":"('fine_tuned_bart_model/tokenizer_config.json',\n 'fine_tuned_bart_model/special_tokens_map.json',\n 'fine_tuned_bart_model/vocab.json',\n 'fine_tuned_bart_model/merges.txt',\n 'fine_tuned_bart_model/added_tokens.json')"},"metadata":{}}],"execution_count":154},{"cell_type":"code","source":"model1 = model ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:32:40.336653Z","iopub.execute_input":"2024-10-18T00:32:40.337675Z","iopub.status.idle":"2024-10-18T00:32:40.341705Z","shell.execute_reply.started":"2024-10-18T00:32:40.337621Z","shell.execute_reply":"2024-10-18T00:32:40.340858Z"}},"outputs":[],"execution_count":156},{"cell_type":"code","source":"# Now, test the model and generate new predictions\ntest_predictions = predictions_df1['prediction'].tolist()  # Your test set predictions\ntest_dataset = PredictionLabelDataset(test_predictions, [''] * len(test_predictions), tokenizer)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n\nmodel1.eval()\ncorrected_predictions = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        # Ensure the inputs are properly converted to tensors and moved to the correct device\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        # Generate corrected predictions\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1)\n\n        # Decode the generated tokens into human-readable text\n        decoded_preds = [\n            tokenizer.decode(pred, skip_special_tokens=True) \n            for pred in predictions\n        ]\n        \n        corrected_predictions.extend(decoded_preds)\n\n# The 'corrected_predictions' now hold the model's new predictions\nprint(corrected_predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:33:59.358828Z","iopub.execute_input":"2024-10-18T00:33:59.359556Z","iopub.status.idle":"2024-10-18T00:34:00.980359Z","shell.execute_reply.started":"2024-10-18T00:33:59.359514Z","shell.execute_reply":"2024-10-18T00:34:00.979330Z"}},"outputs":[{"name":"stdout","text":"['otro feñor por fus recibirimos y occilim,imimimimim,,,,', 'cos juyzios de dame tiempo, para,,,,,,,,,,,,,,,,,,,,,,,', 'que en vueltra educacion lo mani.,,,,', 'feñale, pues me hallo tantos me des,,,,,aleale,,,,ale,,,alealealealealealealeale,,,,aleale,,\\xa0\\xa0\\xa0\\xa0', 'ha tendida en esta camz, a vna en,,,,,,,,,,,,,,,,,,', 'feradad tal, que de de de fis princi.........................................,,,,,,ad,,,adadad,,,,..,,..............', 'g me amenaza con la muerte, y,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'yn elra orlandad en ciemos años,,,,,,,,,,,,,,,,,,', 'ali pues como os di al mundo con,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0oo', 'llolores, con los de Can peñofos ac.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..', 'cidences, os procuro en caminac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'aora a Dios, y que renazcays de mia,,,,,, de,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0', 'para el, por medio de la virud, a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'que os exporto con estos documenoo,,,....', 'cos ( que he recogido con el de fue,,,,,,,,,,,,,', 'lo podible y juzgando es la mas etti........................................ y,,,,.................', 'noble herencia que puedo dexaros,,,,,,,,,,,,,,,,', 'en prendas del encrañable amor,,,,,,,,,', 'que os tengo, por este, y en primer,,,,,,,,:,,,:...,,.\\xa0\\xa0\\xa0', 'lugar por el que deueys a Dios,os,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'pido, y encargo, que me libre laa la la la la la la la la la la la la la la la la la la,, la la la,,,,,,,,,,,,,,,,,,,,,,', 'paga en el puntual exercicio de los,,,,,,,,,,,,,,,,,,,,,', 'y en premio os promero ( con mi,,,:,,.', 'bendicion, que deido aqui os doy),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'de parte de Dios los doze mas ex-,,,', 'colontes que vnestroestro de cipiri-----------------------------------------------------------,,,-,,,,,-,------------------------------', 'cu largamente eferiue, y don en fu,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'ma que condra fu diuina Magcstad,,,,', 'prouidencia particular de volotros,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'y os concedera la gracia del Egiri................', 'cu Santo, sus conolaciones, y lum.,,,,,,,,,,,,,,,,,,.,,,,,', 'bre sobre natural, la alegria de la,,,,,,,,,,,,,,,,,,,,,,,.,,,,.,,,,', 'buena conciencia, la esperança en la,,,,,,,,,,,,,,,,,,,,,,,encia,,,,,,,,,,,,,,', 'diuina mifericordia, la verdadera li,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'bercad, y paz interior, oydo grato aa a a a a a a a a a a a a a a a a a a a a a a a a, a a a a a a a a a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, a, a a\\xa0\\xa0\\xa0\\xa0\\xa0', 'vueltras oraciones, su afiltencia, y,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'fauor en los trabajos, y bendiciones,,,,,,,,,,,,,, en,, en,,,,,,,,,,,,', 'que en la Sanca E feritura promete,,,,,,,,,,', 'a los virtuosos de codo lo temporal,,,,,,,,,,', 'y victimmente, glociolo y alegre,,,,,,,,,,,,,,,,,,,,,,,,', 'ho, que cada coda de las por fi pu-,,,,,,,,,,,,,,,,,-,,,,,---\\xa0', 'diera fernos incentuuo para leguir,,,,', 'el camino de la virtud, aunque no,,,,,,,,,,,,,,,,,,,,,,,,', 'nos cuuiera Dios de antemano o-,,,,,,,,,,,,,,..,,,,', 'oligados a ella, por fer el que es, yadosadosados a a a a aados a aadosados a a a a a a a a a a a a a aadosados a a a aados a a a aadosados a aadosadosados a a a aadosadosados,,', 'por los in estimable beneficios qee', 'nerales de la creacion, conferua......ales.alesalesalesalesales,,..........', 'cion, redempcion, justificacion, y,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0', 'predefinacion, a qe de añaden en ca-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'da vno los particulares fuyos. Aqui.,,,,,,,', 'os hago memoria de la calidad quea,,,,,', 'os dio, que fe funda en la excelencia,,,,,,,,,,,,,,,,,', 'de la vidaud, origen de que fe de ríua,,,,,,,,,,,,,,,,,,,,,,', 'qualquiera verdadera nobleza, ya,,,,,,,,,,,,,,za,,,,,za,,,,,,,,za,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'pues es deuda, y electo de la vidaud,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'led cales como ella os obliga a fer;;,,,,,,,,,,,;;;;;;;', 'mirad que no lolo es necesaria, fino,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'forçofa en los nobles la virud, yaaa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,aaaaaaaaaaaaaaaaaaa,,', 'que el que la buica, es el que le,,,,,,,,,,,,,...,,', 'muestra de mas generolo, y noble,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'animo, y como dixo Bruno Sigui-------------------------------------------------------------,,,,,,,,,,,-----------------------------------------', 'no, puede fer mas noble el el clalauo,,,,,,,,,,,,,,,,,,.,,,,\\xa0\\xa0\\xa0\\xa0', 'que fu fuñor, pues confilte la noble.,,,,..,,,,,,,,........', 'za mayor en mas virrud, y nace de,,,,,,,,,,,,,,,,,,,,,,,,,,', 'lla la nobleza, conferuaje en ella,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'poderadaner fi le falla, por ler elererer,,,,,,,,,erererererererererererererererererererererer,,er,er,,,,,,', 'alma, y vida de la nobleza la vidand,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'ella tiene mayor fuerça que todas,,,,,,,,,,,,,,.,,', 'las armas, y can grande claridad, que,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'aunque este en lugar obícuro, a fi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'nifma feij luz como la mas rica,,,,,,,,,,,,,,,', 'de las piedras, qe es el Carbonco, fola,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'ella es fuficience premio del virtuo--------------,,,,,,,-,,---------------------', 'foles can noble, que ni puede rfar,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'mal de nada, ni cada mal della, y el,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0', 'lugaro proprio, y aliento suyo es el,,,,,,,o,,o,,,,,oo,,,,o,,,,,,,,,,,,,,,o,,,ooo,,,,,,,,,,o,,,o,..::', 'mas excelence, pues en el hombre,,,,,,,,,,,,,,,,,', 'es el coraçon, y en el mundo los,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'Principes, y Reyes; esta lola es laa,,,,,,,,,;,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,;;', 'que quita el tencimiento de las ef-....,,..............', 'pinas de la vida, y contra ella no,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'ien en las calamidades mas fuerza,,,,,,,,,,,,,', 'que la niebla contra el Sol. Socra-------------,,,------------', 'ces pregunado por lorgias, fito----------,,,,,,,,,,,,----------------\\xa0--', 'niz por dichofo al Rey de Porña,,,,,,,,,,,,,,,,,,,,', 'refpondio: No puedo juzgar de el-,,:,,,:::,,,:::::::::::::::::::::::', 'lo, sin haber quando virtud tiene. Y..,,,,,,,,.,,,,,,,,,....\\xa0\\xa0....\\xa0\\xa0\\xa0\\xa0', 'conforma con esto lo que Seneca,,,,,,,,,,', 'defpues de largos difueños conclu--------------------------,-,,,,,-,-------------------', 'ya, de que co ella confilte la bien------------,--,,,,,,,,,------------------------\\xa0\\xa0\\xa0\\xa0--', 'auenturada, y mas felix vida, a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0', 'que añade, que fola la virtud es el,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0', 'propio bien del hombre, pues co.,,,,,,,,,,,,,,,,,,,,,,,,\\xa0 del del del', 'das las de mas co las humanas fe con-.,,,,:,,.......\\xa0.', 'fumen, y ella da muchras de nacu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'raleza etema, no auiendo otra co-,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'pia ( que procuran) pero los mas,,,,,,,,,,,,,,,,,,,,,,,,,', 'los que dexandole lleuar de inci,,,,,,,,,,,', 'naciones de paraudas, y adultadores,,,,,,,,,,,,,,,,,,,,,', 'qe este de la Nobleza y vian mal de,,,,,,,,,,,,,,,za,', 'la autoridad, y rentas con que fe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'hallan, tomando por armas contra,,,,,,,,,,,,,,,,ando,,,,,andoando,andoandoando,,,,,andoandoandoandoandoando', 'Dios, las mercedes que del recibio...,,.,,,,.,.............', 'ron, y de feltimondole, con lo que,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'pienían fe en grandecan, pues en co.anananananananananananananananananananananananananananananan\\xa0\\xa0\\xa0\\xa0', 'das las colas quieren bondad fino,,,,,,,,', 'en fi miños, como dixo San Aguf-------------------------------------------------------------------------------------------------------------', 'cin: y iendo de los que Dand dí::,,::,,::::::::::::::::', 'no conocieron la honra en que fue....on..', 'ron criados, y la pucieron en lo que,,,,,,,,,,,,os,osos,,,,,,,\\xa0\\xa0\\xa0\\xa0', 'mas los abatió, pues confiliendo laa la,,,óóó,,,,,', 'verdadera en feruir, y agradar aa, a a a,, a a a,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0', 'Dios, venos qe dan en hazerfe otros,,,,,,,,,,,,,,,,,,,,,,,..,,', 'lectarios, y cabeças mostruolas de de de de de de de de de de de de de de de,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'vicios, profellando vnos la valen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'cia ( en ellos falla y cial) y otros fer,,,,,,,,,,,:,,,,,,,,,,,,,::\\xa0\\xa0\\xa0\\xa0\\xa0', 'graciolos, burtando el oficio a losos,,,,,,,,,,,,,,,,,,,,,,ososos,ososos,,ososososososososos,,,,.', 'Eruhanes, otros (abios muy por lo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0', 'inchado, vnos enfadados do todos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'y delcorcefes, Poeras con azenos,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'verdads: los locos, y los que mas lo::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::', 'don, enamorados; y llega la de lidichaa,,,,,,,,,,,,,,,', 'de nueltros tiempos á ver baylar,,,,,,::,,', 'como mugeres, nieros de los que,,,,,,,,,,,,,,,,,,,,,,', 'truxeron caîa coda fu vida el pefoononononononononononononononononononononononononon,onon,,,', 'de los Angeles sobre di, y las armas,,,,,,,,,,,,,,,,,..,,,,,', 'en la mano, con que les ganaron,,,,,,,,,,,,,,,,,,,,,,', 'lo que tan indiganamente poifeen.....,..........', 'Tampoco falcan otros, que hazen,,,,,,,,,,,,,,,,,,,,,,,,', 'gracia de exceder en los brindis de de de de de,,,,,,,,,,,,,,,,,,,,,,,', 'los combices, y de no jugar limpio,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'ni eracar verdad, y gala de vivir mu mu mu mu mu mu, mu mu mu mu mu mu mu mu mu,,,,,,,,,,,,arararar,,,,,,,,,,,,,,\\xa0', 'chos años en mal estado ( de feuydo,,,,,,,,', 'digno de fer llorado en España, por,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'la educacion de fus Nobles, y el re,,,,,,,,,,,,,,,,,,,', 'prefontacle yo en estas la firma yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo yo', 'verdades, es como pintaros aqui laa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'fealdad de los ricos, para que con,,,,,,,,,,,,,,,,,,,,,,,ad,,,,,,,,,,,,,,,,', 'horror della les cobrays el aborre,,,,,,,,,,,,,,,,,.,,,', 'cimiento que de llo, creyendo jun.,,,,,.,ooooooo,...,o,', 'tamonce, que la vida del Señor grā------,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0\\xa0', 'de (no contencandofe con huyr de de de de de de de de de de de,,,,, de de,,, de,,,,,,, de de de de de de', 'llos y ha de fer vn continuo exerciendo,,,::,,,:\\xa0\\xa0\\xa0', 'cio de virtudes, porque la magna--------,-,,,,,,,,,,,,,,,,,--------------', 'nima forcaleza, que es la propia, yaa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,zaaleale,,aleale,,,zaza,,,,,ale\\xa0\\xa0\\xa0', 'connaural de los llautres, procede,,,,,,,,,,,,,,,,,,,,,,,,,,', 'de coraçon grande, y este deue del,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,.\\xa0,,', 'preciar la baxeza mayor, que es el,,,,,,,,,,,,,,,,,ar,,,,,,,,,,,,,,,,', 'abarirle a los ricos: legun Acito...,,,.,,,..,,le,,,,,.............', 'celes, y Ciceron, confilte en tres co.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,..', 'las, de feîtimat todas los exteriores,,,,,,,,,::,,,:,,,,,,,,,\\xa0', 'fufeir mucho por la Viraud, y por much much much,,,,,,,, much much,,,,,,,,, much much,ir much,,,,,,,,,,,,,', 'ella acometer arduas y grandes em-,,,,,,', 'pre las en beneficio comun: y la for..', 'caleza Christiana, es fufrir, y hazera,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,a,,,,,,,,,,,,', 'mucho por Dios, y fu fuoria, y bien,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\\xa0\\xa0\\xa0\\xa0', 'de todos, venciendofe vno aji mil.,,,,,,,,,,,,,,,....,.......', 'mo, criunfo a que esta vinculada laaa la la la la,,,,,,,,,,,,,,,,,,,,,,,,', 'verdadera grandeza. Condideradadadad,,,adad,,adad,,,,,,,,,,,', 'pnes, que la honza, y hazienda os laa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'dio Dios para reparcirla, y que,,,,,,,,,,,,,,,,,,,,,,,,,', 'acoys nacido tanto para los de mas,,,,,idoidoidoidoidoidoidoidoidoido,,,,,idoido t t t tido', 'como para vosotifmo. assiendo dío,,,,...,,,,:,,,......\\xa0\\xa0\\xa0.\\xa0\\xa0\\xa0\\xa0', 'Ciceron del Noble, y creed, que,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'don calentos de que le aueys de darosososososososos', 'cuenta muy el trecha, y cargo cona,,,,,,,,,,,,,,,,,,,,,,,,,,,', 'que os ha obligado a fer defendor,,,,.....', 'de fueré y Religion, acerrino per,,,,,,,,,,,,,,,,,,,,,,']\n","output_type":"stream"}],"execution_count":159},{"cell_type":"code","source":"predictions = []\n\n# Set the model to evaluation mode\nmodel.eval()\n\n# Ensure the model is moved to the correct device\nmodel.to(device)\n\nwith torch.no_grad():  # No need to calculate gradients during inference\n    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc=\"Inference\"):\n        image_path = row['image_path']\n        \n        # Open the image as grayscale\n        image = Image.open(image_path).convert(\"L\")  # 'L' mode for grayscale\n        \n        # Transform the image to tensor format\n        transform = transforms.ToTensor()\n        image_tensor = transform(image)  # Shape: [1, H, W] for grayscale\n        \n        # Stack the grayscale image to 3 channels to match model input\n        image_stacked = torch.cat([image_tensor] * 3, dim=0)  # Shape: [3, H, W]\n\n        # Apply threshold transformation\n        mask = image_stacked < 0.6875\n        image_stacked[mask] = 0.0\n        image_stacked[~mask] = 1.0\n\n        # Reshape the image for batch processing\n        image_stacked = image_stacked.unsqueeze(0)  # Add batch dimension, Shape: [1, 3, H, W]\n\n        # Process the image using the processor without rescaling (as per your requirement)\n        pixel_values = processor(image_stacked, return_tensors=\"pt\", do_rescale=False).pixel_values.to(device)\n        \n        # Generate the output using the model\n        outputs = model.generate(pixel_values)\n\n        # Decode the generated output to get the predicted string\n        predicted_string = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        \n        # Append the results to predictions list\n        predictions.append({\n            'unique Id': row['unique Id'],  # Ensure 'unique Id' matches your column name\n            'prediction': predicted_string\n        })\n\n# Create a DataFrame for storing predictions\npredictions_df1 = pd.DataFrame(predictions)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:24:19.031078Z","iopub.execute_input":"2024-10-18T00:24:19.031782Z","iopub.status.idle":"2024-10-18T00:24:52.288664Z","shell.execute_reply.started":"2024-10-18T00:24:19.031739Z","shell.execute_reply":"2024-10-18T00:24:52.287533Z"}},"outputs":[{"name":"stderr","text":"Inference:   0%|          | 0/168 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1338: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nInference: 100%|██████████| 168/168 [00:33<00:00,  5.07it/s]\n","output_type":"stream"}],"execution_count":148},{"cell_type":"code","source":"predictions_df1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:33:24.184942Z","iopub.execute_input":"2024-10-18T00:33:24.188038Z","iopub.status.idle":"2024-10-18T00:33:24.230002Z","shell.execute_reply.started":"2024-10-18T00:33:24.187981Z","shell.execute_reply":"2024-10-18T00:33:24.228667Z"}},"outputs":[{"execution_count":158,"output_type":"execute_result","data":{"text/plain":"    unique Id                              prediction\n0     P_1_L_1  otro feñor por fus recibisimos y occil\n1     P_1_L_2        cos juyzios de dame tiempo, para\n2     P_1_L_3        que en vueltra educacion lo mani\n3     P_1_L_4     feñale, pues me hallo tantos me des\n4     P_1_L_5       ha tendida en esta camz, a vna en\n..        ...                                     ...\n163  P_7_L_20         Ciceron del Noble, y creed, que\n164  P_7_L_21     don calentos de que le aueys de dar\n165  P_7_L_22       cuenta muy el trecha, y cargo con\n166  P_7_L_23       que os ha obligado a fer defendor\n167  P_7_L_24       de fu Eé y Religion, acerrino per\n\n[168 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique Id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P_1_L_1</td>\n      <td>otro feñor por fus recibisimos y occil</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P_1_L_2</td>\n      <td>cos juyzios de dame tiempo, para</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P_1_L_3</td>\n      <td>que en vueltra educacion lo mani</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P_1_L_4</td>\n      <td>feñale, pues me hallo tantos me des</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P_1_L_5</td>\n      <td>ha tendida en esta camz, a vna en</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>P_7_L_20</td>\n      <td>Ciceron del Noble, y creed, que</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>P_7_L_21</td>\n      <td>don calentos de que le aueys de dar</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>P_7_L_22</td>\n      <td>cuenta muy el trecha, y cargo con</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>P_7_L_23</td>\n      <td>que os ha obligado a fer defendor</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>P_7_L_24</td>\n      <td>de fu Eé y Religion, acerrino per</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":158},{"cell_type":"code","source":"# Assuming corrected_predictions is the list of new predictions generated\npredictions_df1['corrected_prediction'] = corrected_predictions\n\n# Check if the new column is added correctly\nprint(predictions_df1.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:35:55.146953Z","iopub.execute_input":"2024-10-18T00:35:55.147722Z","iopub.status.idle":"2024-10-18T00:35:55.156499Z","shell.execute_reply.started":"2024-10-18T00:35:55.147676Z","shell.execute_reply":"2024-10-18T00:35:55.155461Z"}},"outputs":[{"name":"stdout","text":"  unique Id                              prediction  \\\n0   P_1_L_1  otro feñor por fus recibisimos y occil   \n1   P_1_L_2        cos juyzios de dame tiempo, para   \n2   P_1_L_3        que en vueltra educacion lo mani   \n3   P_1_L_4     feñale, pues me hallo tantos me des   \n4   P_1_L_5       ha tendida en esta camz, a vna en   \n\n                                corrected_prediction  \n0  otro feñor por fus recibirimos y occilim,imimi...  \n1  cos juyzios de dame tiempo, para,,,,,,,,,,,,,,...  \n2              que en vueltra educacion lo mani.,,,,  \n3  feñale, pues me hallo tantos me des,,,,,aleale...  \n4  ha tendida en esta camz, a vna en,,,,,,,,,,,,,...  \n","output_type":"stream"}],"execution_count":160},{"cell_type":"code","source":"def add_quotes(value):\n    # Check if the value is not already enclosed in double quotes\n    if not (isinstance(value, str) and value.startswith('\"') and value.endswith('\"')):\n        return f'\"{value}\"'  # Add double quotes\n    return value ","metadata":{"execution":{"iopub.status.busy":"2024-10-17T19:04:07.981383Z","iopub.execute_input":"2024-10-17T19:04:07.981786Z","iopub.status.idle":"2024-10-17T19:04:07.987048Z","shell.execute_reply.started":"2024-10-17T19:04:07.981748Z","shell.execute_reply":"2024-10-17T19:04:07.986136Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def remove_quotes(value):\n    # Check if the value is a string\n    if isinstance(value, str):\n        # Remove leading and trailing double quotes\n        return value.strip('\"')\n    return value","metadata":{"execution":{"iopub.status.busy":"2024-10-17T19:04:09.018271Z","iopub.execute_input":"2024-10-17T19:04:09.019116Z","iopub.status.idle":"2024-10-17T19:04:09.023496Z","shell.execute_reply.started":"2024-10-17T19:04:09.019075Z","shell.execute_reply":"2024-10-17T19:04:09.022597Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions_df['prediction']=predictions_df['prediction'].apply(remove_quotes)\nprint(predictions_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-17T19:04:10.885279Z","iopub.execute_input":"2024-10-17T19:04:10.885992Z","iopub.status.idle":"2024-10-17T19:04:10.895859Z","shell.execute_reply.started":"2024-10-17T19:04:10.885949Z","shell.execute_reply":"2024-10-17T19:04:10.894754Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the 'prediction' column from the dataframe\npredictions_df1 = predictions_df1.drop(columns=['prediction'])\n\n# Check if the column is dropped correctly\nprint(predictions_df1.head())\n#\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:37:43.495719Z","iopub.execute_input":"2024-10-18T00:37:43.496630Z","iopub.status.idle":"2024-10-18T00:37:43.602630Z","shell.execute_reply.started":"2024-10-18T00:37:43.496560Z","shell.execute_reply":"2024-10-18T00:37:43.601322Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","Cell \u001b[0;32mIn[165], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Drop the 'prediction' column from the dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m predictions_df1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions_df1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Check if the column is dropped correctly\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions_df1\u001b[38;5;241m.\u001b[39mhead())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n","\u001b[0;31mKeyError\u001b[0m: \"['prediction'] not found in axis\""],"ename":"KeyError","evalue":"\"['prediction'] not found in axis\"","output_type":"error"}],"execution_count":165},{"cell_type":"code","source":"predictions_df1 = predictions_df1.rename(columns={'corrected_prediction': 'prediction'})\n\n# Check if the column is renamed correctly\nprint(predictions_df1.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-18T00:37:59.292649Z","iopub.execute_input":"2024-10-18T00:37:59.293042Z","iopub.status.idle":"2024-10-18T00:37:59.301783Z","shell.execute_reply.started":"2024-10-18T00:37:59.293005Z","shell.execute_reply":"2024-10-18T00:37:59.300905Z"}},"outputs":[{"name":"stdout","text":"  unique Id                                         prediction\n0   P_1_L_1  otro feñor por fus recibirimos y occilim,imimi...\n1   P_1_L_2  cos juyzios de dame tiempo, para,,,,,,,,,,,,,,...\n2   P_1_L_3              que en vueltra educacion lo mani.,,,,\n3   P_1_L_4  feñale, pues me hallo tantos me des,,,,,aleale...\n4   P_1_L_5  ha tendida en esta camz, a vna en,,,,,,,,,,,,,...\n","output_type":"stream"}],"execution_count":166},{"cell_type":"code","source":"predictions_df1.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-18T00:38:02.772558Z","iopub.execute_input":"2024-10-18T00:38:02.773531Z","iopub.status.idle":"2024-10-18T00:38:02.779956Z","shell.execute_reply.started":"2024-10-18T00:38:02.773490Z","shell.execute_reply":"2024-10-18T00:38:02.778845Z"},"trusted":true},"outputs":[],"execution_count":167},{"cell_type":"code","source":"predictions_df1.head()","metadata":{"execution":{"iopub.status.busy":"2024-10-18T00:38:05.069519Z","iopub.execute_input":"2024-10-18T00:38:05.069977Z","iopub.status.idle":"2024-10-18T00:38:05.081307Z","shell.execute_reply.started":"2024-10-18T00:38:05.069921Z","shell.execute_reply":"2024-10-18T00:38:05.080211Z"},"trusted":true},"outputs":[{"execution_count":168,"output_type":"execute_result","data":{"text/plain":"  unique Id                                         prediction\n0   P_1_L_1  otro feñor por fus recibirimos y occilim,imimi...\n1   P_1_L_2  cos juyzios de dame tiempo, para,,,,,,,,,,,,,,...\n2   P_1_L_3              que en vueltra educacion lo mani.,,,,\n3   P_1_L_4  feñale, pues me hallo tantos me des,,,,,aleale...\n4   P_1_L_5  ha tendida en esta camz, a vna en,,,,,,,,,,,,,...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique Id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P_1_L_1</td>\n      <td>otro feñor por fus recibirimos y occilim,imimi...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P_1_L_2</td>\n      <td>cos juyzios de dame tiempo, para,,,,,,,,,,,,,,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P_1_L_3</td>\n      <td>que en vueltra educacion lo mani.,,,,</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P_1_L_4</td>\n      <td>feñale, pues me hallo tantos me des,,,,,aleale...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P_1_L_5</td>\n      <td>ha tendida en esta camz, a vna en,,,,,,,,,,,,,...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":168},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}